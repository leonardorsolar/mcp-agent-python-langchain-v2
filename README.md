## ğŸ§  Objetivo

> Criamos o **LangGraph** + **LangChain OpenAI** que utilize ferramentas simples para responder ao usuÃ¡rio.

![DescriÃ§Ã£o da imagem](doc/tools.png)

> Agora vamos criar uma agnte com MCP

![DescriÃ§Ã£o da imagem](doc/mcpgif.gif)

## 1ï¸âƒ£ Criar o ambiente do projeto

tenha o python3.10 instalado:

python3.10 --version

depois

```bash
python3.10 -m venv .venv
source .venv/bin/activate
```

---

## 2ï¸âƒ£ Instalar dependÃªncias

```bash
pip install langchain-openai

```

e

```bash
pip install langgraph python-dotenv

```

---

## 3ï¸âƒ£ Criar os arquivos do projeto

```bash
touch main.py tools.py .env
```

---

## 4ï¸âƒ£ ğŸ“ Estrutura final

```
agente_langgraph/
â”œâ”€â”€ .env
â”œâ”€â”€ .gitignore
â”œâ”€â”€ main.py
â”œâ”€â”€ tools.py
â””â”€â”€ .venv/
```

---

### 3. Configure sua API key

Crie um arquivo `.env` na pasta do projeto:

```env
OPENAI_API_KEY=sk-sua_chave_aqui
```

> ğŸ“ **Como obter uma API key:**
>
> 1. Acesse [platform.openai.com](https://platform.openai.com)
> 2. FaÃ§a login ou crie uma conta
> 3. VÃ¡ em "API Keys" e crie uma nova chave
> 4. Copie e cole no arquivo `.env`

Crie o arquivo .gitignore
No arquivo `.gitignore`, adicione:

```gitignore
# Ambiente virtual
.venv/
venv/
env/

# VSCode
.vscode/

# Arquivo de variÃ¡veis de ambiente
.env

# Cache do Python
__pycache__/
*.pyc
*.pyo
*.pyd

# Arquivos de log ou temporÃ¡rios
*.log
*.tmp

# ConfiguraÃ§Ã£o de dependÃªncias (caso seja gerado automaticamente)
pip-wheel-metadata/
*.egg-info/
```

# Parte 1: MCP

Model Context Protocol (MCP) Para Sistemas de IA Generativa

### O Que Ã© o Model Context Protocol (MCP)?

> O Model Context Protocol (MCP) Ã©, essencialmente, um protocolo aberto e universal que padroniza a forma como aplicaÃ§Ãµes de IA interagem com dados e serviÃ§os externos.

> Ã‰ uma especificaÃ§Ã£o aberta criada para padronizar como modelos de linguagem grande (LLMs) e agtentes de IA se conectam a dados, ferramnetas e serviÃ§os externos. LanÃ§ado pela Antropic em novembro de 2024.

-   Em vez de cada sistema de IA precisar de conectores especÃ­ficos para cada fonte de dados (o que resultava no problema â€œM x Nâ€, onde M modelos precisavam integrar com N ferramentas diferentes), o MCP propÃµe um caminho Ãºnico. Com ele, modelos generativos e Agentes de IA podem acessar bases de dados, APIs, arquivos e outras ferramentas atravÃ©s de um protocolo unificado, independentemente de quem forneÃ§a o modelo ou a ferramenta.

![DescriÃ§Ã£o da imagem](doc/mcpmxn.png)

Model Context Protocol (MCP) Ã© um protocolo aberto e um framework open-source concebido para resolver um desafio central da IA moderna: como permitir que modelos de linguagem (LLMs) â€” como Claude, GPT ou outros modelos open-source â€” interajam com ferramentas, serviÃ§os e dados externos de forma padronizada e segura.

![DescriÃ§Ã£o da imagem](doc/mcpcomesem.png)

ğŸ”Œ Muitas vezes descrito como o â€œUSB-C das aplicaÃ§Ãµes de IAâ€, o MCP propÃµe um conector universal que elimina a necessidade de integraÃ§Ãµes manuais e plugins especÃ­ficos para cada sistema. Em vez disso, os modelos que implementam MCP podem ligar-se a qualquer servidor compatÃ­vel â€” desde um Google Drive atÃ© uma base de dados interna â€” usando a mesma estrutura de comunicaÃ§Ã£o.

![DescriÃ§Ã£o da imagem](doc/1751007890194.jpeg)

## Funcionamento bÃ¡sico?

Ã“timo! Vamos fazer um exemplo **bem prÃ¡tico e passo a passo** com os elementos que vocÃª mencionou:

---

## ğŸ”§ **CenÃ¡rio:**

VocÃª tem:

1. **Sua API** (ex: `meu-sistema.com`) â€” onde roda seu cÃ³digo/backend.
2. **API da OpenAI** â€” onde vocÃª envia prompts para o ChatGPT ou GPT-4.
3. **Ferramenta externa: GitHub** â€” que vocÃª quer consultar, por exemplo, para buscar issues ou pull requests de um repositÃ³rio.

E agora vocÃª quer usar **MCP (Model Context Protocol)** para **padronizar a comunicaÃ§Ã£o entre esses componentes**, em vez de fazer "gambiarras" com integraÃ§Ãµes especÃ­ficas para cada ferramenta.

---

## ğŸ“¦ Sem MCP (o jeito tradicional):

-   Seu cÃ³digo chama a OpenAI via REST.
-   A OpenAI nÃ£o consegue acessar diretamente o GitHub.
-   EntÃ£o **vocÃª precisa escrever cÃ³digo** que:

    -   Consulta a API do GitHub.
    -   Pega a resposta.
    -   Formata.
    -   Injeta essa informaÃ§Ã£o no prompt da OpenAI manualmente.

ğŸ‘ Isso Ã© o "problema M x N": muita integraÃ§Ã£o manual.

---

## ğŸ”Œ Com MCP (o jeito padronizado):

-   A **OpenAI (ou Claude)** funciona como **MCP Client**.
-   O **GitHub** (ou um conector para ele) Ã© o **MCP Server**.
-   VocÃª registra o GitHub como uma **ferramenta externa acessÃ­vel via MCP**.
-   A OpenAI pode dizer:
    ğŸ‘‰ "Quero acessar `listIssues` do repositÃ³rio X".

O protocolo MCP define:

-   Como esse pedido deve ser feito.
-   Como o GitHub responde.
-   Tudo isso em um formato padronizado (JSON).

---

## ğŸ“˜ Exemplo real com MCP:

### ğŸ§  Seu LLM (MCP Client) manda isso para o MCP Server:

```json
{
    "tool_call": {
        "name": "github.list_issues",
        "parameters": {
            "repo": "leonardo/meu-projeto",
            "state": "open"
        }
    }
}
```

### ğŸ—ƒï¸ Seu conector GitHub (MCP Server) responde:

```json
{
    "tool_response": {
        "tool_name": "github.list_issues",
        "data": [
            {
                "id": 1,
                "title": "Bug no login",
                "created_at": "2025-07-25T12:00:00Z"
            },
            {
                "id": 2,
                "title": "Melhorar performance da API",
                "created_at": "2025-07-27T09:30:00Z"
            }
        ]
    }
}
```

### ğŸ§  O LLM interpreta essa resposta:

E usa esse conteÃºdo para compor a resposta final ao usuÃ¡rio como:

> "Encontrei 2 issues abertas no repositÃ³rio `leonardo/meu-projeto`: uma sobre login e outra sobre performance."

---

## ğŸ—ï¸ Como vocÃª conecta isso no seu cÃ³digo?

1. **VocÃª implementa um MCP Server** na sua API para expor dados (ex: de um banco interno, GitHub, etc.).
2. VocÃª registra essa ferramenta no agente ou modelo que estÃ¡ usando (Claude, OpenAI, etc.).
3. O modelo pode agora chamar essa ferramenta diretamente via protocolo MCP.

---

## ğŸ”„ Fluxo resumido:

```
UsuÃ¡rio â†’ Sua API â†’ OpenAI (MCP Client) â†’ GitHub (MCP Server) â†’ OpenAI â†’ Sua API â†’ UsuÃ¡rio
```

---

## ğŸ“Œ ConclusÃ£o:

Com **MCP**, sua OpenAI (ou outro LLM) pode conversar com serviÃ§os externos (como GitHub, Notion, Google Drive, seu banco de dados, etc.) sem vocÃª precisar escrever integraÃ§Ãµes especÃ­ficas. Basta os dois lados falarem o **mesmo protocolo**.

Se quiser, posso te mostrar um mini exemplo de cÃ³digo com MCP client/server simulado. Deseja?

### âœ… **O que Ã© o MCP Client?**

O **MCP Client** Ã© geralmente o **modelo de linguagem (LLM)** ou o **agente de IA** que **faz a solicitaÃ§Ã£o** de dados, ferramentas ou serviÃ§os externos. Ele **consome o contexto**.

Ou seja:

-   Ele quer **acessar informaÃ§Ãµes** (ex: documentos, bancos de dados, APIs).
-   Ele envia uma **requisiÃ§Ã£o padronizada** usando o protocolo MCP.
-   Exemplo: Claude, ChatGPT, ou qualquer LLM compatÃ­vel com MCP atuando como "cliente".

ğŸ§  **Pense nele como:**

> â€œO cÃ©rebro que pergunta: Me diga o que tem nesse banco de dadosâ€ ou â€œBusque o histÃ³rico do cliente Xâ€.

---

![DescriÃ§Ã£o da imagem](doc/MCP2-3.gif)

### âœ… **O que Ã© o MCP Server?**

O **MCP Server** Ã© o **serviÃ§o externo**, **base de dados** ou **ferramenta** que **responde** Ã s requisiÃ§Ãµes feitas pelo cliente MCP.

Ou seja:

-   Ele **expÃµe dados ou funcionalidades** via o protocolo MCP.
-   Ele entende as mensagens do MCP Client e responde de forma padronizada.
-   Pode ser: Google Drive, Notion, API REST, MySQL, ERP da empresa, etc.

ğŸ—‚ï¸ **Pense nele como:**

> â€œO servidor que responde: Aqui estÃ£o os dados que vocÃª pediuâ€ ou â€œAqui estÃ¡ a resposta da API que vocÃª requisitouâ€.

---

### ğŸ§© Analogia com cliente-servidor tradicional:

| Papel        | Analogia Web   | MCP Contexto                          |
| ------------ | -------------- | ------------------------------------- |
| **Cliente**  | Navegador Web  | LLM ou Agente de IA (Claude, GPT)     |
| **Servidor** | Site / API Web | Banco de dados, API externa, arquivos |

---

### ğŸ’¡ Exemplo de fluxo:

1. Um agente LLM recebe a tarefa: "Me diga quanto esse cliente gastou no Ãºltimo ano".
2. Ele atua como **MCP Client** e envia uma requisiÃ§Ã£o via MCP.
3. O **MCP Server** que representa o banco de dados da empresa responde com os dados.
4. O LLM processa os dados e responde ao usuÃ¡rio final com a anÃ¡lise.

---

Estudar:
https://www.decodeai.in/what-is-mcp-model-context-protocol-and-why/
